{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d0/7p4xxyy97qbb5_f74yjfh9vw0000gp/T/ipykernel_13048/3921425368.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(f'{root_path}/data/pt/waves.pt')\n",
      "/var/folders/d0/7p4xxyy97qbb5_f74yjfh9vw0000gp/T/ipykernel_13048/3921425368.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data_medium = torch.load(f'{root_path}/data/pt/waves-medium-m3.pt')\n"
     ]
    }
   ],
   "source": [
    "root_path = '../../'\n",
    "\n",
    "data = torch.load(f'{root_path}/data/pt/waves.pt')\n",
    "data_medium = torch.load(f'{root_path}/data/pt/waves-medium-m3.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Ballybunnion \t\t torch.Size([433, 5]) torch.Size([433])\n",
      "1 Belmullet_Inner \t\t torch.Size([433, 5]) torch.Size([433])\n",
      "2 Belmullet_Outer \t\t torch.Size([433, 5]) torch.Size([433])\n",
      "3 Brandon_Bay \t\t torch.Size([433, 5]) torch.Size([433])\n",
      "4 Cork_SmartBuoy \t\t torch.Size([433, 5]) torch.Size([433])\n",
      "5 Finnis \t\t torch.Size([433, 5]) torch.Size([433])\n",
      "6 Killard \t\t torch.Size([433, 5]) torch.Size([433])\n",
      "7 M2 \t\t torch.Size([433, 5]) torch.Size([433])\n",
      "8 M3 \t\t torch.Size([433, 5]) torch.Size([433])\n",
      "9 M4 \t\t torch.Size([433, 5]) torch.Size([433])\n",
      "10 M5 \t\t torch.Size([433, 5]) torch.Size([433])\n",
      "11 M6 \t\t torch.Size([433, 5]) torch.Size([433])\n",
      "12 Mace_Head \t\t torch.Size([433, 5]) torch.Size([433])\n",
      "13 South_Hunter \t\t torch.Size([433, 5]) torch.Size([433])\n",
      "14 Spiddal \t\t torch.Size([433, 5]) torch.Size([433])\n",
      "15 Splaugh \t\t torch.Size([433, 5]) torch.Size([433])\n"
     ]
    }
   ],
   "source": [
    "for index, (key, value) in enumerate(data.items()):\n",
    "    print(index, key, '\\t\\t', value['features'].shape, value['target'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_data = []\n",
    "\n",
    "for key, value in data.items():\n",
    "    train_ratio = 0.8\n",
    "    train_size = int(len(value['features']) * train_ratio)\n",
    "    \n",
    "    X_train, X_test = value['features'][:train_size], value['features'][train_size:]\n",
    "    y_train, y_test = value['target'][:train_size], value['target'][train_size:]\n",
    "    \n",
    "    train_test_data.append({\n",
    "        'name': key,\n",
    "        'X_train': X_train,\n",
    "        'X_test': X_test,\n",
    "        'y_train': y_train,\n",
    "        'y_test': y_test\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ballybunnion \t\t torch.Size([346, 5]) torch.Size([87, 5]) torch.Size([346]) torch.Size([87])\n",
      "Belmullet_Inner \t\t torch.Size([346, 5]) torch.Size([87, 5]) torch.Size([346]) torch.Size([87])\n",
      "Belmullet_Outer \t\t torch.Size([346, 5]) torch.Size([87, 5]) torch.Size([346]) torch.Size([87])\n",
      "Brandon_Bay \t\t torch.Size([346, 5]) torch.Size([87, 5]) torch.Size([346]) torch.Size([87])\n",
      "Cork_SmartBuoy \t\t torch.Size([346, 5]) torch.Size([87, 5]) torch.Size([346]) torch.Size([87])\n",
      "Finnis \t\t torch.Size([346, 5]) torch.Size([87, 5]) torch.Size([346]) torch.Size([87])\n",
      "Killard \t\t torch.Size([346, 5]) torch.Size([87, 5]) torch.Size([346]) torch.Size([87])\n",
      "M2 \t\t torch.Size([346, 5]) torch.Size([87, 5]) torch.Size([346]) torch.Size([87])\n",
      "M3 \t\t torch.Size([346, 5]) torch.Size([87, 5]) torch.Size([346]) torch.Size([87])\n",
      "M4 \t\t torch.Size([346, 5]) torch.Size([87, 5]) torch.Size([346]) torch.Size([87])\n",
      "M5 \t\t torch.Size([346, 5]) torch.Size([87, 5]) torch.Size([346]) torch.Size([87])\n",
      "M6 \t\t torch.Size([346, 5]) torch.Size([87, 5]) torch.Size([346]) torch.Size([87])\n",
      "Mace_Head \t\t torch.Size([346, 5]) torch.Size([87, 5]) torch.Size([346]) torch.Size([87])\n",
      "South_Hunter \t\t torch.Size([346, 5]) torch.Size([87, 5]) torch.Size([346]) torch.Size([87])\n",
      "Spiddal \t\t torch.Size([346, 5]) torch.Size([87, 5]) torch.Size([346]) torch.Size([87])\n",
      "Splaugh \t\t torch.Size([346, 5]) torch.Size([87, 5]) torch.Size([346]) torch.Size([87])\n"
     ]
    }
   ],
   "source": [
    "for i in train_test_data:\n",
    "    print(i['name'], '\\t\\t', i['X_train'].shape, i['X_test'].shape, i['y_train'].shape, i['y_test'].shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### start with a simple linear model treating the data as tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLinear(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim = 1):\n",
    "        super(SimpleLinear, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n-step ahead prediction using the same linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Loss (10 runs) for station Ballybunnion: 0.6738 meters\n",
      "\n",
      "Average Loss (10 runs) for station Belmullet_Inner: 1.2132 meters\n",
      "\n",
      "Average Loss (10 runs) for station Belmullet_Outer: 1.5384 meters\n",
      "\n",
      "Average Loss (10 runs) for station Brandon_Bay: 0.3272 meters\n",
      "\n",
      "Average Loss (10 runs) for station Cork_SmartBuoy: 2.1586 meters\n",
      "\n",
      "Average Loss (10 runs) for station Finnis: 1.0010 meters\n",
      "\n",
      "Average Loss (10 runs) for station Killard: 0.8424 meters\n",
      "\n",
      "Average Loss (10 runs) for station M2: 1.1234 meters\n",
      "\n",
      "Average Loss (10 runs) for station M3: 0.9604 meters\n",
      "\n",
      "Average Loss (10 runs) for station M4: 1.8894 meters\n",
      "\n",
      "Average Loss (10 runs) for station M5: 1.8926 meters\n",
      "\n",
      "Average Loss (10 runs) for station M6: 2.4110 meters\n",
      "\n",
      "Average Loss (10 runs) for station Mace_Head: 0.7994 meters\n",
      "\n",
      "Average Loss (10 runs) for station South_Hunter: 1.5795 meters\n",
      "\n",
      "Average Loss (10 runs) for station Spiddal: 0.6131 meters\n",
      "\n",
      "Average Loss (10 runs) for station Splaugh: 1.1501 meters\n"
     ]
    }
   ],
   "source": [
    "n = 12  # n-step ahead prediction\n",
    "runs = 10\n",
    "num_epochs = 500\n",
    "learning_rate = 0.001\n",
    "\n",
    "for station in train_test_data:\n",
    "    runs = 10\n",
    "    total_avg_loss = 0\n",
    "\n",
    "    X_train = station['X_train'][:n * -1]\n",
    "    X_test = station['X_test'][:n * -1]\n",
    "    \n",
    "    y_train = station['y_train'][n:]\n",
    "    y_test = station['y_test'][n:]\n",
    "    \n",
    "    model = MLP(X_train.shape[1], 32)\n",
    "\n",
    "    criterion = nn.L1Loss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    num_epochs = 1000\n",
    "\n",
    "    for run in range(runs):\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            outputs = model(X_train).squeeze()\n",
    "            \n",
    "            loss = criterion(outputs, y_train)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(X_test).squeeze()\n",
    "            loss = criterion(y_pred, y_test)\n",
    "            # print(f'Final Loss: {loss.item():.4f} meters')\n",
    "            total_avg_loss += loss.item()\n",
    "\n",
    "    print()\n",
    "    station_name = station['name']\n",
    "    print(f'Average Loss ({runs} runs) for station {station_name}: {total_avg_loss / runs:.4f} meters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Medium dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xm_train, Xm_test, ym_train, ym_test = train_test_split(Xm, ym, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tabular prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Loss (10 runs): 0.9412 meters\n"
     ]
    }
   ],
   "source": [
    "runs = 10\n",
    "total_avg_loss = 0\n",
    "\n",
    "# model = SimpleLinear(Xm_train.shape[1])\n",
    "model = MLP(Xm_train.shape[1], 32)\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "for run in range(runs):\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        outputs = model(Xm_train).squeeze()\n",
    "        \n",
    "        loss = criterion(outputs, ym_train)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(Xm_test).squeeze()\n",
    "        loss = criterion(y_pred, ym_test)\n",
    "        # print(f'Final Loss: {loss.item():.4f} meters')\n",
    "        total_avg_loss += loss.item()\n",
    "        \n",
    "print()\n",
    "print(f'Average Loss ({runs} runs): {total_avg_loss / runs:.4f} meters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n-step ahead prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([89503, 8]) torch.Size([89503])\n",
      "torch.Size([22376, 8]) torch.Size([22376])\n"
     ]
    }
   ],
   "source": [
    "n = 24 # each step is 1 hour\n",
    "\n",
    "Xmn = Xm[:n * -1]\n",
    "ymn = ym[n:]\n",
    "\n",
    "train_size = int(0.8 * len(Xmn))\n",
    "\n",
    "Xm_train, Xm_test = Xmn[:train_size], Xmn[train_size:]\n",
    "ym_train, ym_test = ymn[:train_size], ymn[train_size:]\n",
    "\n",
    "print(Xm_train.shape, ym_train.shape)\n",
    "print(Xm_test.shape, ym_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Loss (10 runs): 1.1371 meters\n"
     ]
    }
   ],
   "source": [
    "runs = 10\n",
    "total_avg_loss = 0\n",
    "\n",
    "# model_mn = SimpleLinear(Xm_train.shape[1])\n",
    "model_mn = MLP(Xm_train.shape[1], 32)\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model_mn.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "for run in range(runs):\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model_mn.train()\n",
    "        outputs = model_mn(Xm_train).squeeze()\n",
    "        \n",
    "        loss = criterion(outputs, ym_train)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model_mn.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model_mn(Xm_test).squeeze()\n",
    "        loss = criterion(y_pred, ym_test)\n",
    "        # print(f'Final Loss: {loss.item():.4f} meters')\n",
    "        total_avg_loss += loss.item()\n",
    "\n",
    "print()\n",
    "print(f'Average Loss ({runs} runs): {total_avg_loss / runs:.4f} meters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NC 41025 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d0/7p4xxyy97qbb5_f74yjfh9vw0000gp/T/ipykernel_8788/1621255091.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dataNC = torch.load('../data/pt/waves-41025.pt')\n"
     ]
    }
   ],
   "source": [
    "dataNC = torch.load('../data/pt/waves-41025.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xnc = dataNC['features']\n",
    "ync = dataNC['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Xnc, ync, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([41784, 9]) torch.Size([41784])\n",
      "torch.Size([10447, 9]) torch.Size([10447])\n"
     ]
    }
   ],
   "source": [
    "n = 6 # each step is 10 minutes\n",
    "\n",
    "Xn = Xnc[:n * -1]\n",
    "yn = ync[n:]\n",
    "\n",
    "train_size = int(0.8 * len(Xn))\n",
    "\n",
    "X_train, X_test = Xn[:train_size], Xn[train_size:]\n",
    "y_train, y_test = yn[:train_size], yn[train_size:]\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: 647.7593 meters\n",
      "Epoch 051: 14.9001 meters\n",
      "Epoch 101: 6.6098 meters\n",
      "Epoch 151: 2.6699 meters\n",
      "Epoch 201: 2.6367 meters\n",
      "Epoch 251: 2.4404 meters\n",
      "Epoch 301: 9.1784 meters\n",
      "Epoch 351: 2.0719 meters\n",
      "Epoch 401: 2.7606 meters\n",
      "Epoch 451: 1.1368 meters\n"
     ]
    }
   ],
   "source": [
    "modelNC = SimpleLinear(X_train.shape[1])\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(modelNC.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 500\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    modelNC.train()\n",
    "    outputs = modelNC(X_train).squeeze()\n",
    "    \n",
    "    loss = criterion(outputs, y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # print epoch\n",
    "    if epoch % (num_epochs // 10) == 0:\n",
    "        print(f'Epoch {epoch + 1:03d}: {loss.item():.4f} meters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Loss: 8.6745 meters\n"
     ]
    }
   ],
   "source": [
    "modelNC.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = modelNC(X_test).squeeze()\n",
    "    loss = criterion(y_pred, y_test)\n",
    "    print(f'Final Loss: {loss.item():.4f} meters')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wave-forecasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
